{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dieljr/pythonDev/blob/master/HousePriceIowa_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIY18YvQXwSI"
      },
      "source": [
        "# Nesta série vou investigar o dataset House Price of Aime, Iwoa.  Ao contrário do PIMA INDIANS DIABETES (último post) este conjunto é mais complexo, principalmente do ponto de vista da engenharia de dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-KptzMzXwSM"
      },
      "source": [
        "Fonte: http://jse.amstat.org/v19n3/decock.pdf da pesquisa.\n",
        "Fonte: https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data do dataset"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "mmGS09QUXwSN"
      },
      "source": [
        "Ao final do processo nós devemos prever preços, então estamos falando de uma variável dependente do tipo contínua, logo a classe de algoritmo é a de REGRESSÃO.\n",
        "Temos diversas opões para tanto, mas usaremos três: Linear Regression, Naive Bayes, Suport Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okjL22EUXwSO"
      },
      "outputs": [],
      "source": [
        "# Carregar pacotes iniciais\n",
        "\n",
        "# explorar dados\n",
        "import pandas as pd\n",
        "\n",
        "# estatísticas\n",
        "import numpy as np\n",
        "\n",
        "# Visualizações\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "%matplotlib inline\n",
        "mpl.rcParams['figure.dpi'] = 400\n",
        "\n",
        "import seaborn as sb"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "KiVpzzU2XwSP"
      },
      "source": [
        "DICIONÁRIO DO DATASET:\n",
        "\n",
        "SalePrice - the property's sale price in dollars. This is the target variable that you're trying to predict.\n",
        "\n",
        "MSSubClass: The building class\n",
        "MSZoning: The general zoning classification\n",
        "LotFrontage: Linear feet of street connected to property\n",
        "LotArea: Lot size in square feet\n",
        "Street: Type of road access\n",
        "Alley: Type of alley access\n",
        "LotShape: General shape of property\n",
        "LandContour: Flatness of the property\n",
        "Utilities: Type of utilities available\n",
        "LotConfig: Lot configuration\n",
        "LandSlope: Slope of property\n",
        "Neighborhood: Physical locations within Ames city limits\n",
        "Condition1: Proximity to main road or railroad\n",
        "Condition2: Proximity to main road or railroad (if a second is present)\n",
        "BldgType: Type of dwelling\n",
        "HouseStyle: Style of dwelling\n",
        "OverallQual: Overall material and finish quality\n",
        "OverallCond: Overall condition rating\n",
        "YearBuilt: Original construction date\n",
        "YearRemodAdd: Remodel date\n",
        "RoofStyle: Type of roof\n",
        "RoofMatl: Roof material\n",
        "Exterior1st: Exterior covering on house\n",
        "Exterior2nd: Exterior covering on house (if more than one material)\n",
        "MasVnrType: Masonry veneer type\n",
        "MasVnrArea: Masonry veneer area in square feet\n",
        "ExterQual: Exterior material quality\n",
        "ExterCond: Present condition of the material on the exterior\n",
        "Foundation: Type of foundation\n",
        "BsmtQual: Height of the basement\n",
        "BsmtCond: General condition of the basement\n",
        "BsmtExposure: Walkout or garden level basement walls\n",
        "BsmtFinType1: Quality of basement finished area\n",
        "BsmtFinSF1: Type 1 finished square feet\n",
        "BsmtFinType2: Quality of second finished area (if present)\n",
        "BsmtFinSF2: Type 2 finished square feet\n",
        "BsmtUnfSF: Unfinished square feet of basement area\n",
        "TotalBsmtSF: Total square feet of basement area\n",
        "Heating: Type of heating\n",
        "HeatingQC: Heating quality and condition\n",
        "CentralAir: Central air conditioning\n",
        "Electrical: Electrical system\n",
        "1stFlrSF: First Floor square feet\n",
        "2ndFlrSF: Second floor square feet\n",
        "LowQualFinSF: Low quality finished square feet (all floors)\n",
        "GrLivArea: Above grade (ground) living area square feet\n",
        "BsmtFullBath: Basement full bathrooms\n",
        "BsmtHalfBath: Basement half bathrooms\n",
        "FullBath: Full bathrooms above grade\n",
        "HalfBath: Half baths above grade\n",
        "Bedroom: Number of bedrooms above basement level\n",
        "Kitchen: Number of kitchens\n",
        "KitchenQual: Kitchen quality\n",
        "TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n",
        "Functional: Home functionality rating\n",
        "Fireplaces: Number of fireplaces\n",
        "FireplaceQu: Fireplace quality\n",
        "GarageType: Garage location\n",
        "GarageYrBlt: Year garage was built\n",
        "GarageFinish: Interior finish of the garage\n",
        "GarageCars: Size of garage in car capacity\n",
        "GarageArea: Size of garage in square feet\n",
        "GarageQual: Garage quality\n",
        "GarageCond: Garage condition\n",
        "PavedDrive: Paved driveway\n",
        "WoodDeckSF: Wood deck area in square feet\n",
        "OpenPorchSF: Open porch area in square feet\n",
        "EnclosedPorch: Enclosed porch area in square feet\n",
        "3SsnPorch: Three season porch area in square feet\n",
        "ScreenPorch: Screen porch area in square feet\n",
        "PoolArea: Pool area in square feet\n",
        "PoolQC: Pool quality\n",
        "Fence: Fence quality\n",
        "MiscFeature: Miscellaneous feature not covered in other categories\n",
        "MiscVal: $Value of miscellaneous feature\n",
        "MoSold: Month Sold\n",
        "YrSold: Year Sold\n",
        "SaleType: Type of sale\n",
        "SaleCondition: Condition of sale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxsKwS2WXwSR"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17V4r0RfXwSR"
      },
      "outputs": [],
      "source": [
        "print(type(train))\n",
        "print(type(test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBhiArNpXwST"
      },
      "outputs": [],
      "source": [
        "print(train.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jwk1BKxlXwST"
      },
      "source": [
        "São incríveis 80 colunas de variáveis independentes e 1 dependente (SalePrice)!\n",
        "Então o objetivo de negócio é prever o preço o imóvel baseados nas melhores variáveis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aWlY7F6XwSU"
      },
      "outputs": [],
      "source": [
        "train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dF0Bkz5SXwSV"
      },
      "outputs": [],
      "source": [
        "del train['Id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_oKswJkXwSV"
      },
      "outputs": [],
      "source": [
        "del test['Id']"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "qreN-ouWXwSW"
      },
      "source": [
        "Acontece que para algoritmos de regressão é exigido variáveis quantitativas(categóricas), e vemos que boa parte do dataset tem variáveis qualitativas.\n",
        "Vamos investigar essas variáveis qualitativas e saber o que podemos fazer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeEXgk65XwSW"
      },
      "outputs": [],
      "source": [
        "# valores NAN plotados\n",
        "mpl.rcParams['figure.figsize'] = (15,10)\n",
        "plt.hist(train.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWsqvIAKXwSX"
      },
      "outputs": [],
      "source": [
        "# Função que verifica como estão divididas as variáveis qualitativas por subcategorias?\n",
        "def unicos_obj(df):\n",
        "    for i in df.select_dtypes(include = 'object'):\n",
        "        print(i, '', df[i].unique())\n",
        "unicos_obj(train)\n",
        "unicos_obj(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jy3YKy1nXwSX"
      },
      "outputs": [],
      "source": [
        "# Função que converte 'other' e suas VARIAÇÕES em 'Other'\n",
        "def na_other_obj(df):\n",
        "    for i in df:\n",
        "        df[i].replace('Oth', 'Other', inplace = True)\n",
        "        df[i].replace('OthW', 'Other', inplace = True)\n",
        "        df[i].replace('Othr', 'Other', inplace = True)\n",
        "        df[i].replace('other', 'Other', inplace = True)\n",
        "        \n",
        "na_other_obj(train)\n",
        "na_other_obj(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5q1PuvB0XwSY"
      },
      "outputs": [],
      "source": [
        "# Função que identifica variáveis com alto coeficiente de variação (> 25%)\n",
        "med_x = []\n",
        "std_x = []\n",
        "cv_x = []\n",
        "var_i = []\n",
        "def analise_cv(df):\n",
        "    cont_std = 0\n",
        "    for i in df.select_dtypes(include = 'number'):\n",
        "        \n",
        "        med, std = df[i].mean(), df[i].std() # média e desvio pádrão\n",
        "        cv = (std / med)*100 # coeficiente de variação\n",
        "        \n",
        "        var_i.append(i)\n",
        "        med_x.append(med)\n",
        "        std_x.append(std)\n",
        "        cv_x.append(cv)\n",
        "        \n",
        "        if cv > 25: # valor de corte\n",
        "            cont_std += 1\n",
        "            \n",
        "            #print(i)\n",
        "            #print('média de ',round(med))\n",
        "            #print('desvio padrão de ', round(std))\n",
        "            #print('Coeficiente de variação = ',  round(cv))\n",
        "            #print('')   \n",
        "            \n",
        "    \n",
        "    print('O conjunto de dados tem ', cont_std, ' variáveis com desvio padrão acima de 25%')\n",
        "    #print('')\n",
        "    \n",
        "    \n",
        "analise_cv(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STrD66O3XwSY"
      },
      "outputs": [],
      "source": [
        "# Tabela com média, desvio padrão e coeficiente de variação de cada variável numérica\n",
        "print(pd.DataFrame({'variavel':var_i,\n",
        "                       'media':med_x,\n",
        "                       'desvio_padrao': std_x,\n",
        "                       'coeficiente_variacao': cv_x}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeV65Q12XwSZ"
      },
      "outputs": [],
      "source": [
        "# Função que verifica valores missing das variáveis numéricas\n",
        "def missing_num(df):\n",
        "    for i in df:\n",
        "        print(i, '', df[i].isna().sum())\n",
        "\n",
        "missing_num(train.select_dtypes(include = 'number'))\n",
        "missing_num(test.select_dtypes(include = 'number'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJ8-1gi9XwSZ"
      },
      "outputs": [],
      "source": [
        "# Função que substitui os valores MISSING pela média de cada coluna numérica\n",
        "def na_media(df):\n",
        "    for i in df:\n",
        "        df[i].fillna(df[i].mean(), inplace = True)\n",
        "        \n",
        "\n",
        "na_media(train.select_dtypes(include = 'number'))\n",
        "na_media(test.select_dtypes(include = 'number'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDghipwfXwSa"
      },
      "outputs": [],
      "source": [
        "# identificação de OUTLIERS em uma distribuição normal\n",
        "\n",
        "from IPython.display import Image\n",
        "Image ('outlier normal distribution.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgQ7wVPoXwSa"
      },
      "outputs": [],
      "source": [
        "# Função para plotagem de valores outliers\n",
        "def box_plot(df):\n",
        "    plt.figure(figsize = (10,8))\n",
        "    df.boxplot()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yk46So4lXwSa"
      },
      "outputs": [],
      "source": [
        "# plot valores numéricos outliers no data set treino\n",
        "box_plot(train.select_dtypes(include = 'number'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2wmMJOAXwSb"
      },
      "outputs": [],
      "source": [
        "# plot valores numéricos outliers no data set test\n",
        "box_plot(test.select_dtypes(include = 'number'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_etzv0L6XwSb"
      },
      "outputs": [],
      "source": [
        "preco_antigo = train['SalePrice'] # para usar na comparação ante e depois dos autliers e da normalização (log10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCXMRNeaXwSb"
      },
      "outputs": [],
      "source": [
        "# pacote para remoção de outliers\n",
        "from scipy.stats import zscore, iqr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b9U5F7UXwSb"
      },
      "outputs": [],
      "source": [
        "# Função que elimina valores extremos (0,25 < x > 0.75).\n",
        "def remove_outlier(df):\n",
        "    \n",
        "    iqr(df, axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXSPoiO-XwSc"
      },
      "outputs": [],
      "source": [
        "# chamada à função de remoção de outliers\n",
        "# inclui um filtro para variáveis númericas\n",
        "        \n",
        "remove_outlier(train.select_dtypes(include = 'number'))\n",
        "remove_outlier(test.select_dtypes(include = 'number'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avRU9YhOXwSc"
      },
      "outputs": [],
      "source": [
        "# função que normaliza o dataset\n",
        "\n",
        "def normal(df):\n",
        "    for i in df.select_dtypes(include = 'number'):\n",
        "        df[i] = np.log10(df[i])\n",
        "\n",
        "normal(train)\n",
        "normal(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOqD_BD3XwSc"
      },
      "outputs": [],
      "source": [
        "# compara o antes e o depois da normalização\n",
        "\n",
        "comp_precos = {'original':preco_antigo, 'normalizado':train['SalePrice']}\n",
        "df_plot = pd.DataFrame(comp_precos)\n",
        "mpl.rcParams['figure.figsize'] = (20,8)\n",
        "df_plot.hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNqoG5BBXwSc"
      },
      "outputs": [],
      "source": [
        "# Mostra as colunas categóricas para serem usadas na trasnformação (np.get_dummies)\n",
        "print(train.select_dtypes(include = 'object').columns)\n",
        "print('')\n",
        "print(test.select_dtypes(include = 'object').columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ows6INzNXwSd"
      },
      "outputs": [],
      "source": [
        "#Aplicar transformação das variáveis categóricas para numéricas\n",
        "\n",
        "train = pd.get_dummies(train, columns = ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
        "       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
        "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
        "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
        "       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
        "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
        "       'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n",
        "       'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',\n",
        "       'SaleType', 'SaleCondition'])\n",
        "\n",
        "test = pd.get_dummies(test, columns = ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
        "       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
        "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
        "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
        "       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
        "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
        "       'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n",
        "       'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',\n",
        "       'SaleType', 'SaleCondition'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "styYBNRfXwSd"
      },
      "source": [
        "#                                    ANÁLISE APÓS TRATAMENTOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ip3ab-owXwSd"
      },
      "outputs": [],
      "source": [
        "train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IC9eyn4NXwSd"
      },
      "outputs": [],
      "source": [
        "# Remover os valores infinitos (inf, -inf)\n",
        "train = train.replace([np.inf, -np.inf], np.nan)\n",
        "test = test.replace([np.inf, -np.inf], np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqjgOTGeXwSe"
      },
      "outputs": [],
      "source": [
        "train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvhNqM8TXwSe"
      },
      "outputs": [],
      "source": [
        "train.fillna(train.mean(), inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4a68ItJXwSe"
      },
      "outputs": [],
      "source": [
        "test.fillna(test.mean(), inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-pF20nnXwSe"
      },
      "outputs": [],
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7q0rrdhXwSf"
      },
      "source": [
        "# ENTRAREMOS NO PREPROCESSAMENTO"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "og2sTgRxXwSf"
      },
      "source": [
        "O PCA tem a função reduzir dataset de grandes dimensões selecionando as características mais importantes.\n",
        "Para aplicar o PCA é necessário normalizar o dataset primeiro!\n",
        "\n",
        "Como já foram feitas as transformações nos conjuntos de dados TRAIN e TEST, ótimo!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7-aSy8yXwSf"
      },
      "outputs": [],
      "source": [
        "# subconjunto com variáveis independentes\n",
        "X = train.drop(['SalePrice'], axis = 1)\n",
        "\n",
        "# subconjunto com a variável dependente\n",
        "y = train['SalePrice']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBIjxYKKXwSf"
      },
      "outputs": [],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoVuLGKcXwSg"
      },
      "outputs": [],
      "source": [
        "# Veficar as dimensões dos subconjuntos\n",
        "\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VFyUu92XwSg"
      },
      "outputs": [],
      "source": [
        "# Carregar pacotes para preprocessamento e machine learning\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, LassoCV, Ridge\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import LinearSVR\n",
        "\n",
        "# explained_variance_score: essa metrica é a função da pontuação da regressão da variancia explicada: varia de 0 a 1, \n",
        "# sendo 1 = ótimo.\n",
        "# na minha opinião, o mais importante para esse dataset é manter o padrão (uniform_average), mas você pode tentar outros\n",
        "\n",
        "# A outra métrica é r2_score: todos nós já sabemos como é importante o valor de R2, que varia de 0 a 1.\n",
        "from sklearn.metrics import explained_variance_score, r2_score, SCORERS\n",
        "\n",
        "from scipy.stats.stats import pearsonr\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHUnkWx4XwSg"
      },
      "source": [
        "# MACHINE LEARNING: Linear Regression"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "zuGRZZdPXwSg"
      },
      "source": [
        "O principal parametro desta regressão linear talvez seja:\n",
        "o PENALTY (‘l1’, ‘l2’, ‘elasticnet’, ‘none’) e;\n",
        "o SOLVER (‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’)\n",
        "\n",
        "Existe uma certa combinação entre esses dois parametros, portanto cuidado, dê aquela olhada na documentação.\n",
        "\n",
        "Vou usar padrão do algoritmo e depois fazer aguma alteração nestes dois paramentros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsqSSO-WXwSh"
      },
      "outputs": [],
      "source": [
        "# Função para testar tamanho da amostra e n_component do PCA no algoritmo de Regressão Linear\n",
        "\n",
        "rs = []\n",
        "nc = []\n",
        "r2s = []\n",
        "scoreev = []\n",
        "\n",
        "for i in range(10, 30):\n",
        "    for j in range(100, 500, 10):\n",
        "    # separar treinos e testes\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = j)\n",
        "        soma_j = 100 + j\n",
        "\n",
        "        lr = LinearRegression()\n",
        "        evs = explained_variance_score\n",
        "\n",
        "        # Aplicar automação para n_component\n",
        "        pca = PCA(n_components=i)\n",
        "        X_train = pca.fit_transform(X_train)\n",
        "        X_test = pca.transform(X_test)\n",
        "        taxas = pca.explained_variance_ratio_\n",
        "\n",
        "        # Treinar o modelo\n",
        "        model_lr = lr.fit(X_train, y_train)\n",
        "\n",
        "        # Criar o modelo de predição\n",
        "        pred_lr = lr.predict(X_test)\n",
        "        pred_lr.shape\n",
        "\n",
        "        # Avaliar o modelo com r2_score\n",
        "        r2 = r2_score(y_true = y_test, y_pred = pred_lr)\n",
        "\n",
        "        # Avaliar o modelo com explained_variance_score\n",
        "        score_ev = evs(y_true = y_test, y_pred = pred_lr)\n",
        "        \n",
        "        rs.append(soma_j)\n",
        "        nc.append(i)\n",
        "        r2s.append(r2)\n",
        "        scoreev.append(score_ev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0rZ8X99XwSh"
      },
      "outputs": [],
      "source": [
        "scores_lr = pd.DataFrame(columns = ['n_component','random_state', 'r2_score', 'evs'], data = (list(zip(nc, rs, r2s, scoreev))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDNAfjQrXwSh"
      },
      "outputs": [],
      "source": [
        "# n-component e ramdom_state pulam de 10 em 10\n",
        "scores_lr.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXJdlbSsXwSh"
      },
      "outputs": [],
      "source": [
        "# apresentação do melhor escore entre a variação de n_component e random_state\n",
        "melhor_score_lr_ncomp = scores_lr.groupby('n_component')[['r2_score', 'evs']].max(); melhor_score_lr_ncomp.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPgr40ZUXwSi"
      },
      "outputs": [],
      "source": [
        "# Resumo dos escores\n",
        "scores_lr.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MkCBzjlXwSi"
      },
      "outputs": [],
      "source": [
        "# Função que avalia o rmse (root mean squared error) com Cross Validation\n",
        "def rmse(modelo):\n",
        "    rmse = np.sqrt(-cross_val_score(modelo,\n",
        "                               X_train,\n",
        "                               y_train,\n",
        "                               scoring = 'neg_mean_squared_error',\n",
        "                               cv = 5))\n",
        "    return(rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cz-v2uMIXwSi"
      },
      "outputs": [],
      "source": [
        "# Resultado das cinco rodadas do erro quadrado médio\n",
        "rmse(model_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rGuw0-5XwSi"
      },
      "outputs": [],
      "source": [
        "# Resultado da média do RMSE\n",
        "rmse(model_lr).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "Cx9ztaJmXwSj"
      },
      "outputs": [],
      "source": [
        "# Visualização da reta de regressão treinada\n",
        "sb.jointplot(x = y_test, y = pred_lr, kind = 'reg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "c_tSztx8XwSj"
      },
      "outputs": [],
      "source": [
        "# Visualização do resumo estatísitco\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula as smf\n",
        "from statsmodels.regression.linear_model import OLSResults\n",
        "\n",
        "reg = sm.OLS(y, X).fit()\n",
        "\n",
        "print(reg.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nmb1K3YuXwSj"
      },
      "outputs": [],
      "source": [
        "# Cria uma série de dados\n",
        "reg_coef = pd.Series(reg.pvalues, index = X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OG-jl6xdXwSj"
      },
      "outputs": [],
      "source": [
        "# Concatena duas lista de dados para selecionar os menores valores de P-Values\n",
        "coef_imp = pd.concat([reg_coef.sort_values(ascending = False).head(0), reg_coef.sort_values(ascending = True).head(34)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AXPkdCoXwSk"
      },
      "outputs": [],
      "source": [
        "# Cria um plot das variáveis com valor de p (< 0.05)\n",
        "# são 34 variáveis com p_value desejável\n",
        "plt.figure(figsize=(10,8))\n",
        "coef_imp.sort_values().plot(kind = 'bar')\n",
        "\n",
        "plt.ylabel('Análise p < 0.05')\n",
        "plt.title('Melhores Variáveis para Linear Regression com P-Value < 0.05')\n",
        "plt.plot([0.05,0.05,0.05,0.05,0.05,0.05], 'r--')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dutd6BRwXwSk"
      },
      "outputs": [],
      "source": [
        "# Concatena duas lista de dados para selecionar os maiores valores de P-Values\n",
        "coef_imp = pd.concat([reg_coef.sort_values(ascending = False).head(254), reg_coef.sort_values(ascending = True).head(0)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbKIrXLfXwSk"
      },
      "outputs": [],
      "source": [
        "# Cria um plot das variáveis com valor de p (< 0.05)\n",
        "# são 34 variáveis com p_value desejável\n",
        "plt.figure(figsize=(10,8))\n",
        "coef_imp.sort_values().plot(kind = 'bar')\n",
        "\n",
        "plt.ylabel('Análise p < 0.05')\n",
        "plt.title('Piores Variáveis para Linear Regression com P-Value > 0.05')\n",
        "plt.plot([0.05,0.05,0.05,0.05,0.05,0.05], 'r--')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "_VzyovbNXwSk"
      },
      "source": [
        "O resumo estatístico revelou alto R e R2. O R2 (coeficiente de determinação) que significa \"reta explicada\" e diz o quanto os dados estão próximos da reta. Entre 0 e 1, quanto maior o valor melhor.\n",
        "\n",
        "O baixo EIGENVALUES indica que há problemas de MULTICOLINEARIDADE, por isso o alto valor de R e R2 e das acurácias e menor erro. Isso quer dizer que os coeficientes de algumas variáveis são tendenciosas para o modelo.\n",
        "\n",
        "Se o P-Value for (< 0.05) indica que se pode rejeitar a hipótese nula, ou seja, que existe um forte relacionamento entre as variáveis, e que a tal variável ajuda a explicar a variável target.\n",
        "\n",
        "\n",
        "Pela análise do P_value, pode-se identificar quais são as possíveis variáveis que podem ser excluídas para reduzir ou eliminar a multicolinearidade. Quanto maior o valor de P-Value, menos importante \n",
        "\n",
        "Neste caso, podemos realizar uma FEATURE SELECTION para melhorar a regressão linear ou usar LASSO, que já faz essa escolha automaticamente.\n",
        "\n",
        "Para melhorar esse algoritmo (Linear Regression):\n",
        "a) selecionar variáveis mais segnificativas com p-value < 0.05: usar o index das variáveis com p-value < 0.05 (coef_imp(..).index)\n",
        "b) excluir variáveis que causam multicolinearidade: usar o VIF (variance_inflation_factor do pacote statsmodel)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Buw7XhB4XwSl"
      },
      "source": [
        "# MACHINE LEARNING: Lasso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdwOfmqAXwSl"
      },
      "source": [
        "Lasso significa \"Least Absolute Shrinkage and Selection Operator\" ou operação(regularização e regressão) e seleção mínimo absoluto.\n",
        "Isso siginifica que LASSO faz a regularização das variáveis, bem como a seleção destas em ordem de acurácia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "228tUepUXwSl"
      },
      "outputs": [],
      "source": [
        "# subconjunto com variáveis independentes\n",
        "X = train.drop(['SalePrice'], axis = 1)\n",
        "\n",
        "# subconjunto com a variável dependente\n",
        "y = train['SalePrice']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TflZqgEXwSl"
      },
      "outputs": [],
      "source": [
        "# Função para testar melhor amostragem para LASSO\n",
        "\n",
        "rs_ls = []\n",
        "r2s_ls = []\n",
        "scoreev_ls = []\n",
        "\n",
        "\n",
        "for j in range(100, 500, 10):\n",
        "    # separar treinos e testes\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = j)\n",
        "    soma_j = 100 + j\n",
        "    \n",
        "    # Manter os parametros padrão\n",
        "    ls = LassoCV(cv = 5, random_state = 100, alphas = [1, 0.01, 0.001, 0.0005])\n",
        "    \n",
        "    # Treinar o modelo\n",
        "    model_ls = ls.fit(X_train, y_train)\n",
        "    model_ls.score(X, y)\n",
        "\n",
        "    # Criar o modelo de predição\n",
        "    pred_ls = model_ls.predict(X_test)\n",
        "\n",
        "    # Avaliar o modelo com r2_score\n",
        "    r2_ls = r2_score(y_true = y_test, y_pred = pred_ls)\n",
        "\n",
        "    # Avaliar o modelo com explained_variance_score\n",
        "    score_ls = evs(y_true = y_test, y_pred = pred_ls)\n",
        "    \n",
        "    rs_ls.append(soma_j)\n",
        "    r2s_ls.append(r2_ls)\n",
        "    scoreev_ls.append(score_ls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WTb7Tm5XwSl"
      },
      "outputs": [],
      "source": [
        "\n",
        "scores_ls = pd.DataFrame(columns = ['random_state', 'r2_score', 'evs'], data = (list(zip(rs_ls, r2s_ls, scoreev_ls))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YVQUQtRXwSm"
      },
      "outputs": [],
      "source": [
        "scores_ls.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMs1JS-4XwSm"
      },
      "outputs": [],
      "source": [
        "melhor_score_ls_ncomp = scores_ls.groupby('random_state')[['r2_score', 'evs']].max(); melhor_score_ls_ncomp.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2Pr6FWNXwSm"
      },
      "outputs": [],
      "source": [
        "# Resumo dos escores\n",
        "scores_ls.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5AYKTwmXwSm"
      },
      "outputs": [],
      "source": [
        "# Erro médio qudrado para o modelo LASSO\n",
        "rmse(model_ls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EmaxBTKXwSn"
      },
      "outputs": [],
      "source": [
        "# Erro médio do modelo LASSO\n",
        "print(rmse(model_ls).mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAA-sXb0XwSn"
      },
      "outputs": [],
      "source": [
        "lasso_coef = pd.Series(model_ls.coef_, index = X_train.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hi0yHAfiXwSn"
      },
      "outputs": [],
      "source": [
        "ls_melhor_coef = pd.concat([lasso_coef.sort_values(ascending = True).head(5), lasso_coef.sort_values(ascending = False).head(20)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KM9_F-SXwSn"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "ls_melhor_coef.plot(kind = 'barh')\n",
        "plt.xlabel('Valor')\n",
        "plt.title('Representatitvidade das Melhores Variáveis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5mT7cAUXwSn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L99yXnQCXwSo"
      },
      "outputs": [],
      "source": [
        "ax = plt.gca()\n",
        "\n",
        "ax.plot(alphas*2, coef)\n",
        "ax.set_xscale('log')\n",
        "plt.axis('tight')\n",
        "plt.xlabel('alpha')\n",
        "plt.ylabel('weights')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uS51paUVXwSo"
      },
      "outputs": [],
      "source": [
        "ax = plt.gca()\n",
        "\n",
        "ax.plot(alphas, lasso_coef)\n",
        "ax.set_xscale('log')\n",
        "plt.axis('tight')\n",
        "plt.xlabel('alpha')\n",
        "plt.ylabel('Standardized Coefficients')\n",
        "plt.title('Lasso coefficients as a function of alpha');"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "XPDyBomRXwSo"
      },
      "source": [
        "Melhor performance para LASSO do que Linear Regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hHb9pP4XwSo"
      },
      "source": [
        "# MACHINE LEARNING: SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fzr9xsVXwSo"
      },
      "source": [
        "SVM ou Support Vector Machine: Esse algoritmo, após análise, reconhe os padrões. É um algoritmo não probabilístico. \n",
        "Ele faz o tratamento de outliers.Não é aconselhado para dataset muito grandes. Os suportes são os separadores dos grupos.    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P22WcJXKXwSp"
      },
      "outputs": [],
      "source": [
        "# subconjunto com variáveis independentes\n",
        "X = train.drop(['SalePrice'], axis = 1)\n",
        "\n",
        "# subconjunto com a variável dependente\n",
        "y = train['SalePrice']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIXPD4ctXwSp"
      },
      "outputs": [],
      "source": [
        "# Função para testar tamanho da amostra e n_component do PCA no algoritmo de Regressão Linear\n",
        "\n",
        "rs_svm = []\n",
        "r2s_svm = []\n",
        "scoreev_svm = []\n",
        "\n",
        "\n",
        "for j in range(100, 500, 10):\n",
        "    # separar treinos e testes\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = j)\n",
        "\n",
        "    # Normalizar datasets\n",
        "    # Só normalizamos a variável dependente\n",
        "    #sc = StandardScaler()\n",
        "    #X_train = sc.fit_transform(X_train)\n",
        "    #X_test = sc.transform(X_test)\n",
        "\n",
        "    svm = LinearSVR()\n",
        "\n",
        "    # Treinar o modelo\n",
        "    model_svm = svm.fit(X_train, y_train)\n",
        "\n",
        "    # Criar o modelo de predição\n",
        "    pred_svm = svm.predict(X_test)\n",
        "\n",
        "    # Avaliar o modelo com r2_score\n",
        "    r2_svm = r2_score(y_true = y_test, y_pred = pred_svm)\n",
        "\n",
        "    # Avaliar o modelo com explained_variance_score\n",
        "    score_svm = evs(y_true = y_test, y_pred = pred_svm)\n",
        "\n",
        "    rs_svm.append(soma_j)\n",
        "    r2s_svm.append(r2)\n",
        "    scoreev_svm.append(score_svm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS7G9DdiXwSp"
      },
      "outputs": [],
      "source": [
        "scores_svm = pd.DataFrame(columns = ['random_state', 'r2_score', 'evs'], data = (list(zip(rs_svm, r2s_svm, scoreev_svm))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfDoK2MYXwSp"
      },
      "outputs": [],
      "source": [
        "scores_svm.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNUCEsI6XwSq"
      },
      "outputs": [],
      "source": [
        "melhor_score_svm_ncomp = scores_svm.groupby('random_state')[['r2_score', 'evs']].max(); melhor_score_ls_ncomp.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-CZa9bhXwSq"
      },
      "outputs": [],
      "source": [
        "# Resumo dos escores\n",
        "scores_svm.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4wNAX5RXwSq"
      },
      "outputs": [],
      "source": [
        "svm_coef = pd.Series(model_svm.coef_, index = X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9n9uXBQXwSq"
      },
      "outputs": [],
      "source": [
        "svm_melhor_coef = pd.concat([svm_coef.sort_values(ascending = True).head(10), svm_coef.sort_values(ascending = False).head(10)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDf3o0UKXwSq"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "svm_melhor_coef.plot(kind = 'barh')\n",
        "plt.xlabel('Valor')\n",
        "plt.title('Melhores Variáveis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khrkaQ5pXwSr"
      },
      "outputs": [],
      "source": [
        "# Plotagem da comparação da regressão dos modelos testados\n",
        "plt.figure(figsize = (10,8))\n",
        "\n",
        "sb.jointplot(x = y_test, y = pred_lr, kind = 'reg', color='b')\n",
        "plt.ylabel('Linear Regression')\n",
        "plt.legend(['regressão', 'novos dados'], ncol = 2, loc = \"lower right\")\n",
        "\n",
        "sb.jointplot(x = y_test, y = pred_ls, kind = 'reg', color = 'g')\n",
        "plt.ylabel('Lasso - Cross Validation')\n",
        "plt.legend(['regressão', 'novos dados'], ncol = 2, loc = \"lower right\")\n",
        "\n",
        "sb.jointplot(x = y_test, y = pred_svm, kind = 'reg', color = 'r')\n",
        "plt.ylabel('Support Vector Machine')\n",
        "plt.legend(['regressão', 'novos dados'], ncol = 2, loc = \"lower right\")\n",
        "\n",
        "plt.suptitle('Comparação entre os modelos Linear Regression, Lasso e SVM')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uyvj9ZgNXwSr"
      },
      "outputs": [],
      "source": [
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x61UjJpvXwSr"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "HousePriceIowa-Final.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}